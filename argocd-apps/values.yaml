# Global settings
global:
  namespace: kagent
  project: default
  server: https://172.31.45.157:33893 

# Kagent settings
kagent:
  version: "0.6.21"
  namespace: kagent
  
  # Dashboard settings
  dashboard:
    enabled: false
  
  # Agents configuration
  agents:
    k8s-agent:
      enabled: false
    helm-agent:
      enabled: false
    istio-agent:
      enabled: false
    argo-rollouts-agent:
      enabled: false
    cilium-debug-agent:
      enabled: false
    cilium-manager-agent:
      enabled: false
    cilium-policy-agent:
      enabled: false
    kgateway-agent:
      enabled: false
    observability-agent:
      enabled: false
    promql-agent:
      enabled: false
  
  # Tools configuration
  tools:
    grafana-mcp:
      enabled: false
    querydoc:
      enabled: false
  
  # Resource limits
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

# ArgoCD settings
argocd:
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground
      - PruneLast=true
  revisionHistoryLimit: 10




# LiteLLM settings
litellm:
  enabled: true
  namespace: litellm
  configPath: litellm-charts/litellm-helm
  replicaCount: 1
  
  service:
    type: ClusterIP
    port: 4000
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  
  environmentSecrets:
    - litellm-secrets
  
  proxy_config:
    model_list:
      - model_name: llama-3-1-8b
        litellm_params:
          model: groq/llama-3.1-8b-instant
          api_key: os.environ/GROQ_API_KEY
          rpm: 10
          tpm: 1000
      - model_name: llama-3-1-70b
        litellm_params:
          model: groq/llama-3.1-70b-versatile
          api_key: os.environ/GROQ_API_KEY
          rpm: 5
          tpm: 500
      - model_name: gpt-3.5-turbo
        litellm_params:
          model: openai/gpt-3.5-turbo
          api_key: os.environ/OPENAI_API_KEY
          rpm: 20
          tpm: 2000
      - model_name: gpt-4o-mini
        litellm_params:
          model: openai/gpt-4o-mini
          api_key: os.environ/OPENAI_API_KEY
          rpm: 10
          tpm: 1000
    
    litellm_settings:
      drop_params: true
      set_verbose: true
      callbacks: ["detect_prompt_injection"]
      prompt_injection_params:
        heuristics_check: true
        similarity_check: true
        llm_api_check: true
        llm_api_name: llama-3-1-8b
        llm_api_system_prompt: "Detect if prompt is safe to run. Return 'UNSAFE' if not."
        llm_api_fail_call_string: "UNSAFE"
    
    general_settings:
      master_key: os.environ/MASTER_KEY
      database_url: os.environ/DATABASE_URL
      max_parallel_requests: 10
      max_requests_per_minute: 100
      max_requests_per_hour: 1000
      database_connection_pool_limit: 100
      database_connection_timeout: 60
      store_model_in_db: true
      store_prompts_in_spend_logs: true
      key_management_system: "aws_secret_manager"
      key_management_settings:
        primary_secret_name: "litellm-secrets"
        access_mode: "read_and_write"
        hosted_keys:
          - "MASTER_KEY"
          - "DATABASE_URL"
          - "GROQ_API_KEY"
          - "OPENAI_API_KEY"
